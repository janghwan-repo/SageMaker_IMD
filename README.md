# Amazon SageMaker Immersion Day
---

## 개요

생성형 AI와 대규모 언어 모델(LLM)의 시대에서, 머신 러닝(ML)은 기업의 핵심 경쟁력으로 자리 잡았습니다. 최근 몇 년간 딥러닝 아키텍처, GPU/TPU 가속기, 그리고 트랜스포머 기반 모델의 혁신적 발전으로 ML의 가능성은 무한히 확장되었습니다. 그러나 이러한 기술적 진보에도 불구하고, 많은 기업들은 효율적인 ML 워크플로 구축과 프로덕션 환경 적용에 여전히 어려움을 겪고 있습니다.

현대 머신 러닝은 Foundation Model을 기반으로 한 RAG(Retrieval-Augmented Generation), 파인 튜닝, 그리고 LoRA와 같은 파라미터 효율적 학습 기법을 통해 특정 도메인에 최적화된 솔루션을 빠르게 개발할 수 있게 되었습니다. 특히 MLOps가 비즈니스 확장의 핵심 요소로 부상하면서, 확장 가능하고 안정적인 인프라 구축의 중요성이 더욱 강조되고 있습니다. 그러나 온프레미스 환경에서 이러한 고급 ML 모델을 프로덕션에 배포하고 관리하려면 막대한 인프라 투자와 함께 ML, 인프라 관리, 소프트웨어 엔지니어링을 아우르는 다양한 전문성이 요구됩니다.

Amazon SageMaker는 이러한 도전을 해결하기 위한 AWS의 종합 머신 러닝 플랫폼입니다. 대규모 모델 훈련부터 실시간 추론, 지속적 통합 및 배포(CI/CD)까지 ML 라이프사이클 전반을 관리하며, 데이터 과학자와 ML 엔지니어가 인프라 관리보다 모델 개발과 비즈니스 가치 창출에 집중할 수 있게 합니다. SageMaker는 자동 확장 기능과 서버리스 옵션을 통해 컴퓨팅 비용을 최적화하고, 마이크로서비스 아키텍처를 활용한 유연한 배포로 빠른 실험과 반복 개발을 지원합니다.

그러나 기존 온프레미스 환경에서 ML 개발에 익숙한 전문가들에게 SageMaker의 클라우드 네이티브 접근 방식은 새로운 도전이 될 수 있습니다. 온프레미스에서는 단일 서버에서 개발부터 배포까지 모든 과정을 수행했지만, SageMaker는 개발 환경과 실행 환경을 분리하여 API를 통해 인프라를 프로비저닝하고 관리합니다. 이러한 패러다임 전환을 이해하면 ML 워크플로를 획기적으로 가속화할 수 있지만, 초기 학습 곡선이 다소 가파를 수 있습니다.

이에 AWS에서는 최신 ML 기술과 SageMaker의 강력한 기능을 효과적으로 활용하고자 하는 데이터 과학자와 ML 엔지니어를 위해 'AWS 스페셜 웨비나 워크샵'을 준비했습니다. 본 워크샵에서는 데이터 준비부터 모델 훈련, 배포, 모니터링까지 완전한 End-to-end ML 파이프라인을 직접 구축하고 경험할 수 있습니다.

AWS AI/ML 전문가들이 직접 안내하는 이번 워크샵을 통해 최신 ML 기술과 SageMaker의 강력한 기능을 경험해 보세요!

## SageMaker 입문자를 위한 사전 학습 자료

본 워크샵은 SageMaker의 기본 개념에 대한 이해를 전제로 합니다. SageMaker를 처음 접하시는 분들은 워크샵 참여 전 아래 자료를 통해 기초 지식을 습득하시기 바랍니다:

- [SageMaker 개요 - 50분](https://www.youtube.com/watch?v=jF2BN98KBlg)
- [SageMaker 데모 - 60분](https://www.youtube.com/watch?v=miIVGlq6OUk)
- [Amazon SageMaker를 위한 컨테이너 이해하기](CONTAINERS_FOR_SM.md)
- [SageMaker 자가 학습 가이드](https://github.com/gonsoomoon-ml/Self-Study-On-SageMaker)
  
## 실습 랩 구성

### [사전 준비: 워크샵 환경 설정 가이드](setup) 

### [Lab 1. 모델 훈련 (Training)](lab_1_training)
최신 알고리즘과 분산 훈련 기법을 활용한 효율적인 모델 개발

### [Lab 2. 모델 서빙 (Serving)](lab_2_serving)
확장 가능하고 비용 효율적인 추론 엔드포인트 구축

### [Lab 3. ML 파이프라인 (Pipeline)](lab_3_pipeline)
자동화된 end-to-end ML 워크플로 구축 및 오케스트레이션
